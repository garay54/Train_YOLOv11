# ğŸš€ Entrenamiento de YOLOv11 con OptimizaciÃ³n AutomÃ¡tica de HiperparÃ¡metros

Este proyecto implementa un sistema de entrenamiento automatizado para modelos YOLOv11 de segmentaciÃ³n de instancias, utilizando **Optuna** para la optimizaciÃ³n automÃ¡tica de hiperparÃ¡metros. El objetivo es entrenar un modelo de detecciÃ³n y segmentaciÃ³n de grietas en concreto.

## ğŸ“‹ DescripciÃ³n

Este proyecto estÃ¡ diseÃ±ado para:

- **Entrenar modelos YOLOv11-seg** (segmentaciÃ³n de instancias) para detectar grietas en imÃ¡genes de concreto
- **Optimizar automÃ¡ticamente hiperparÃ¡metros** usando Optuna (Tree-structured Parzen Estimator)
- **Evaluar mÃºltiples configuraciones** de forma sistemÃ¡tica y encontrar la mejor combinaciÃ³n de parÃ¡metros
- **Generar visualizaciones** de la evoluciÃ³n de las mÃ©tricas durante la optimizaciÃ³n

### CaracterÃ­sticas principales:

- âœ… OptimizaciÃ³n automÃ¡tica de hiperparÃ¡metros (tamaÃ±o de imagen, batch size, learning rate, optimizador, etc.)
- âœ… Manejo robusto de errores (especialmente errores de memoria GPU)
- âœ… VisualizaciÃ³n de resultados con grÃ¡ficos de evoluciÃ³n
- âœ… Resumen automÃ¡tico de las mejores configuraciones encontradas
- âœ… Soporte para GPU con limpieza automÃ¡tica de memoria

## ğŸ—ï¸ Estructura del Proyecto

```
Train_YOLOv11/
â”œâ”€â”€ train_yolo11.py          # Script principal de entrenamiento y optimizaciÃ³n
â”œâ”€â”€ data.yaml                 # ConfiguraciÃ³n del dataset (rutas y clases)
â”œâ”€â”€ yolo11s-seg.pt           # Modelo base pre-entrenado (YOLOv11-seg small)
â”œâ”€â”€ train/                    # ImÃ¡genes y etiquetas de entrenamiento
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ valid/                    # ImÃ¡genes y etiquetas de validaciÃ³n
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ test/                     # ImÃ¡genes y etiquetas de prueba
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â””â”€â”€ runs/                     # Resultados de entrenamiento
    â””â”€â”€ optuna_search/        # Resultados de la optimizaciÃ³n
```

## ğŸ”§ Requisitos Previos

### 1. Python y Dependencias

AsegÃºrate de tener Python 3.8 o superior instalado. Luego instala las dependencias:

```bash
pip install ultralytics optuna pyyaml matplotlib torch torchvision
```

### 2. GPU (Recomendado)

Para entrenar modelos YOLOv11 de manera eficiente, se recomienda tener una GPU NVIDIA con CUDA instalado. El script detectarÃ¡ automÃ¡ticamente si hay GPU disponible.

### 3. Dataset

El proyecto utiliza un dataset de detecciÃ³n de grietas en concreto con:
- **3,717 imÃ¡genes** de entrenamiento
- **200 imÃ¡genes** de validaciÃ³n
- **112 imÃ¡genes** de prueba
- **1 clase**: `crack` (grieta)

## ğŸ“ ConfiguraciÃ³n

### Archivo `data.yaml`

Este archivo define la estructura del dataset:

```yaml
train: train/images
val: valid/images
test: test/images

nc: 1
names: ['crack']
```

### ParÃ¡metros en `train_yolo11.py`

Puedes modificar estos parÃ¡metros segÃºn tus necesidades:

```python
DATASET = "data.yaml"               # Ruta al YAML del dataset
BASE_MODEL = "yolo11s-seg.pt"       # Modelo base pre-entrenado
PROJECT = "runs/optuna_search"      # Carpeta de resultados
DEVICE = "0"                        # GPU ("0", "1", etc.) o "cpu"
EPOCHS = 100                        # Ã‰pocas por prueba
WORKERS = 8                         # Hilos del dataloader
N_TRIALS = 20                       # NÃºmero de combinaciones a probar
```

### HiperparÃ¡metros que se optimizan automÃ¡ticamente:

- **TamaÃ±o de imagen** (`imgsz`): 416, 512, 640 pÃ­xeles
- **Batch size** (`batch`): 8, 16, 32
- **Learning rate inicial** (`lr0`): 1e-4 a 1e-2 (escala logarÃ­tmica)
- **Optimizador**: SGD, Adam, AdamW
- **Momentum**: 0.7 a 0.99
- **Weight decay**: 1e-6 a 1e-3 (escala logarÃ­tmica)

## ğŸš€ Pasos para Ejecutar

### Paso 1: Preparar el Entorno

1. Clona o descarga este repositorio
2. AsegÃºrate de tener todas las dependencias instaladas (ver secciÃ³n de Requisitos)

### Paso 2: Verificar el Dataset

AsegÃºrate de que las carpetas `train/`, `valid/` y `test/` contengan:
- ImÃ¡genes en formato JPG/PNG
- Archivos de etiquetas en formato YOLO (.txt) con el mismo nombre que las imÃ¡genes

### Paso 3: Verificar el Modelo Base

El archivo `yolo11s-seg.pt` debe estar en el directorio raÃ­z. Si no lo tienes, Ultralytics lo descargarÃ¡ automÃ¡ticamente la primera vez que ejecutes el script.

### Paso 4: Ejecutar el Entrenamiento

```bash
python train_yolo11.py
```

### Paso 5: Monitorear el Progreso

Durante la ejecuciÃ³n verÃ¡s:

- âœ… Progreso de cada trial (prueba de hiperparÃ¡metros)
- ğŸ“Š MÃ©tricas en tiempo real (mAP50-95, Recall, Precision)
- âš ï¸ Advertencias si algÃºn trial falla (por ejemplo, por falta de memoria GPU)
- ğŸ Resumen final con las mejores configuraciones

### Paso 6: Revisar los Resultados

Los resultados se guardan en `runs/optuna_search/`:

- **`optuna_best.yaml`**: Mejores hiperparÃ¡metros encontrados
- **`optuna_results_plot.png`**: GrÃ¡fico de evoluciÃ³n de mÃ©tricas
- **`trial_X_*/`**: Carpetas individuales con resultados de cada trial
- **`trial_X_*/weights/best.pt`**: Mejor modelo de cada trial

## ğŸ” CÃ³mo Funciona

### 1. Proceso de OptimizaciÃ³n

El script utiliza **Optuna** con el algoritmo **TPE (Tree-structured Parzen Estimator)**:

1. **InicializaciÃ³n**: Crea un estudio de optimizaciÃ³n que busca maximizar el mAP50-95
2. **BÃºsqueda**: Para cada trial, Optuna sugiere una combinaciÃ³n de hiperparÃ¡metros
3. **Entrenamiento**: Se entrena el modelo YOLOv11 con esos hiperparÃ¡metros
4. **EvaluaciÃ³n**: Se calcula el mAP50-95 del modelo entrenado
5. **Aprendizaje**: Optuna aprende de los resultados y sugiere mejores combinaciones
6. **RepeticiÃ³n**: Se repite el proceso hasta completar `N_TRIALS` trials

### 2. Manejo de Errores

El script incluye manejo robusto de errores:

- **Errores de memoria GPU**: Si un trial falla por falta de memoria, se registra y continÃºa con el siguiente
- **Limpieza automÃ¡tica**: Se limpia la memoria GPU despuÃ©s de cada trial
- **Pruning**: Trials que no mejoran se detienen tempranamente (MedianPruner)

### 3. MÃ©tricas Evaluadas

- **mAP50-95**: Mean Average Precision (promedio de mAP@0.5 a mAP@0.95) - **mÃ©trica principal**
- **Recall**: Tasa de detecciÃ³n de objetos
- **Precision**: PrecisiÃ³n de las detecciones

### 4. VisualizaciÃ³n

Al finalizar, se genera un grÃ¡fico que muestra:
- EvoluciÃ³n del mAP50-95 por trial
- EvoluciÃ³n del Recall por trial
- IdentificaciÃ³n visual de las mejores configuraciones

## ğŸ“Š InterpretaciÃ³n de Resultados

### Archivo `optuna_best.yaml`

Contiene:
```yaml
best_mAP: 0.7234          # Mejor mAP50-95 encontrado
best_params:              # Mejores hiperparÃ¡metros
  imgsz: 640
  batch: 16
  lr0: 0.00123
  optimizer: AdamW
  momentum: 0.937
  weight_decay: 0.0001
best_trial: 15            # NÃºmero del trial que obtuvo el mejor resultado
```

### Mejor Modelo

El mejor modelo se encuentra en:
```
runs/optuna_search/trial_X_*/weights/best.pt
```

Puedes usar este modelo para inferencia o continuar entrenÃ¡ndolo.

## âš™ï¸ PersonalizaciÃ³n

### Cambiar el Modelo Base

Puedes usar diferentes modelos pre-entrenados:
- `yolo11n-seg.pt` (nano - mÃ¡s rÃ¡pido, menos preciso)
- `yolo11s-seg.pt` (small - balanceado) â­ **Recomendado**
- `yolo11m-seg.pt` (medium - mÃ¡s preciso, mÃ¡s lento)
- `yolo11l-seg.pt` (large - muy preciso, muy lento)
- `yolo11x-seg.pt` (xlarge - mÃ¡ximo rendimiento)

### Ajustar el Espacio de BÃºsqueda

En la funciÃ³n `objective()`, puedes modificar los rangos de hiperparÃ¡metros:

```python
imgsz = trial.suggest_categorical("imgsz", [416, 512, 640, 768])  # Agregar mÃ¡s opciones
batch = trial.suggest_categorical("batch", [4, 8, 16, 32])        # Ajustar segÃºn tu GPU
lr0 = trial.suggest_float("lr0", 1e-5, 1e-1, log=True)           # Ampliar rango
```

### Usar CPU en lugar de GPU

Cambia `DEVICE = "cpu"` en la configuraciÃ³n (serÃ¡ mucho mÃ¡s lento).

## ğŸ› SoluciÃ³n de Problemas

### Error: "CUDA out of memory"

- Reduce el `batch` size en el espacio de bÃºsqueda
- Reduce el `imgsz` (tamaÃ±o de imagen)
- Cierra otras aplicaciones que usen GPU
- Reduce `WORKERS`

### Error: "No se encontrÃ³ results.yaml"

- Verifica que el entrenamiento se completÃ³ correctamente
- Revisa los logs del trial especÃ­fico
- Aumenta `EPOCHS` si el entrenamiento se interrumpe muy temprano

### El proceso es muy lento

- Reduce `N_TRIALS` para menos pruebas
- Reduce `EPOCHS` para entrenamientos mÃ¡s cortos (aunque menos precisos)
- Usa un modelo mÃ¡s pequeÃ±o (`yolo11n-seg.pt`)
- AsegÃºrate de estar usando GPU

## ğŸ“š Recursos Adicionales

- [DocumentaciÃ³n de Ultralytics YOLOv11](https://docs.ultralytics.com/)
- [DocumentaciÃ³n de Optuna](https://optuna.readthedocs.io/)
- [Dataset original en Roboflow](https://universe.roboflow.com/university-bswxt/crack-bphdr)

## ğŸ“„ Licencia

Este proyecto utiliza un dataset de dominio pÃºblico. Consulta los archivos `README.roboflow.txt` y `README.dataset.txt` para mÃ¡s informaciÃ³n sobre el dataset.

## ğŸ¤ Contribuciones

Las mejoras y sugerencias son bienvenidas. Algunas ideas:

- Agregar mÃ¡s hiperparÃ¡metros a optimizar
- Implementar early stopping mÃ¡s sofisticado
- Agregar visualizaciÃ³n de importancia de hiperparÃ¡metros
- Exportar modelos en diferentes formatos (ONNX, TensorRT, etc.)

---

**Â¡Feliz entrenamiento! ğŸ¯**

